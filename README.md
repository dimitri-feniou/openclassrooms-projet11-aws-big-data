# OpenClassrooms Projet 11 - AWS Big Data

## Description

Projet de mise en place d'une infrastructure Big Data scalable sur AWS pour la startup **Fruits!**, d√©veloppant une application mobile de classification de fruits.

## Contexte

La startup Fruits! souhaite d√©velopper une application mobile permettant aux utilisateurs de prendre en photo un fruit et d'obtenir des informations sur celui-ci. Pour construire cette fonctionnalit√© de classification, l'entreprise a besoin d'une infrastructure Big Data capable de traiter des millions d'images de mani√®re scalable et √©conomique.
## Lien vers le jeux de donn√©es 

[Jeu de donn√©es fruits](https://www.kaggle.com/moltean/fruits)

## Objectifs

- Compl√©ter un notebook PySpark pour l'extraction de features et la r√©duction de dimensionnalit√©
- D√©ployer la solution sur AWS EMR (Elastic MapReduce)
- Respecter les contraintes RGPD (serveurs en UE)
- Maintenir un budget < 10 EUR

## Technologies utilis√©es

- **AWS EMR** : Cluster Spark manag√©
- **PySpark** : Traitement distribu√© des donn√©es
- **TensorFlow / MobileNetV2** : Extraction de features via deep learning
- **S3** : Stockage des donn√©es et r√©sultats
- **R√©gion AWS** : eu-west-3 (Paris) pour conformit√© RGPD
## Vid√©o de pr√©sentation AWS

üé• [Voir la vid√©o de pr√©sentation AWS](https://github.com/dimitri-feniou/openclassrooms-projet11-aws-big-data/releases/download/vid%C3%A9o/Presentation_video_aws.mp4)

## Architecture

```
Images (S3) ‚Üí PySpark ‚Üí MobileNetV2 (Feature Extraction) ‚Üí PCA ‚Üí R√©sultats (S3)
```

## Fonctionnalit√©s principales

### 1. Broadcast des poids du mod√®le
- Chargement du mod√®le TensorFlow une seule fois sur le driver
- Broadcast des poids vers tous les workers
- **R√©sultat** : Acc√©l√©ration ~6x du traitement (30 min ‚Üí 5 min)

### 2. R√©duction de dimensionnalit√© avec PCA
- R√©duction des features de 1280 √† 50 dimensions
- **R√©sultat** : Compression ~25x du stockage (5 GB ‚Üí 200 MB pour 1M d'images)
- Conservation de 85-90% de la variance

## Fichiers du projet

- **bootstrap-emr.sh** : Script de bootstrap pour installer les librairies Python sur le cluster EMR (TensorFlow, Pillow, pandas, etc.)
- **P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb** : Notebook principal contenant le code PySpark pour l'extraction de features et la PCA
- **Presentation_vid√©o_aws.mp4** : Vid√©o de d√©monstration de l'impl√©mentation AWS
- **config.json** : Configuration Spark et Jupyter pour le cluster EMR
- **jupyter-s3-conf.json** : Configuration de persistance Jupyter sur S3

## Installation et d√©ploiement

### Pr√©requis
- Compte AWS configur√©
- Bucket S3 cr√©√© (ex: `fruit-projet-11-feniou`)
- R√¥les IAM configur√©s (EMR_DefaultRole, EMR_EC2_DefaultRole)

### √âtapes de d√©ploiement

1. **Cr√©er un cluster EMR**
   ```bash
   # R√©gion: eu-west-3 (Paris)
   # Configuration: 1 master + 2-4 core nodes (m5.xlarge)
   # Applications: Spark, Hadoop, JupyterHub
   ```

2. **Uploader les fichiers sur S3**
   ```bash
   aws s3 cp bootstrap-emr.sh s3://votre-bucket/scripts/
   aws s3 cp P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb s3://votre-bucket/notebooks/
   ```

3. **Configurer le bootstrap lors de la cr√©ation du cluster**
   - Ajouter `bootstrap-emr.sh` comme action de bootstrap

4. **Ex√©cuter le notebook**
   - Se connecter √† JupyterHub via l'interface EMR
   - Ouvrir et ex√©cuter le notebook

## R√©sultats

- **Performance** : Traitement de 10 000 images en ~5 minutes avec broadcast
- **Co√ªt** : < 10 EUR pour l'ensemble du projet (optimisation via arr√™t du cluster)
- **Stockage** : R√©duction de 96% de l'espace de stockage gr√¢ce √† la PCA
- **RGPD** : Conformit√© assur√©e avec la r√©gion eu-west-3

## Gestion des co√ªts

**Important** : Pour respecter le budget de 10 EUR :
- Arr√™ter le cluster EMR imm√©diatement apr√®s utilisation
- Utiliser des instances Spot si possible
- Monitorer les co√ªts via AWS Cost Explorer
- Supprimer les donn√©es temporaires sur S3


